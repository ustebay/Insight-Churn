{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file reads data in csv format and uploads to local POSTGRESS database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "os.chdir('/Users/deniz/Research/Insight_Churn/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In Python: Define a database name\n",
    "dbname = 'CHURN'\n",
    "username = 'deniz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgres://deniz@localhost/CHURN\n"
     ]
    }
   ],
   "source": [
    "# 'engine' is connection to postgres database\n",
    "engine = create_engine('postgres://%s@localhost/%s'%(username,dbname))\n",
    "print engine.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# create a database (if it doesn't exist)\n",
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)\n",
    "print(database_exists(engine.url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we read each csv file one by one (making sure date/boolean fields are parsed properly) and then save to database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/Users/deniz/Research/Insight_Churn/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# HOLIDAYS (TIME OFF)\n",
    "dtypes = {'date': 'str', 'shift':'str'}\n",
    "parse_dates = ['date']\n",
    "holidays = pd.read_csv(path + 'provider_holidays.csv',sep=';',\n",
    "                      dtype=dtypes, parse_dates=parse_dates)\n",
    "holidays.loc[holidays['hour']==8,'hour']='morning' \n",
    "holidays.loc[holidays['hour']==13,'hour']='afternoon'\n",
    "holidays.rename(columns = {'hour':'shift'}, inplace = True)\n",
    "# Remove future time-off data\n",
    "holidays = holidays[holidays['date']<'2017-01-20']\n",
    "holidays.to_sql('holidays', engine, if_exists='replace')\n",
    "\n",
    "print holidays.columns.to_series().groupby(holidays.dtypes).groups\n",
    "holidays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PROVIDERS\n",
    "# read a database from CSV and load it into a pandas dataframe\n",
    "dtypes = {'started_datetime': 'str', 'finished_datetime': 'str','birthday':'str'}\n",
    "parse_dates = ['started_datetime', 'finished_datetime','birthday']\n",
    "providers = pd.read_csv(path + 'providers.csv',sep=';',\n",
    "                        dtype=dtypes, parse_dates=parse_dates)\n",
    "providers.to_sql('providers', engine, if_exists='replace')\n",
    "print providers.columns.to_series().groupby(providers.dtypes).groups\n",
    "providers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SERVICES\n",
    "dtypes = {'date': 'str', 'planned_entry_datetime_cache': 'str','provider_checked_in':'str',\n",
    "          'planned_exit_datetime_cache':'str','provider_checked_out':'str'}\n",
    "parse_dates = ['date', 'planned_entry_datetime_cache','provider_checked_in','planned_exit_datetime_cache',\n",
    "               'provider_checked_out']\n",
    "\n",
    "services = pd.read_csv(path + 'services.csv', sep=';',\n",
    "                                               dtype=dtypes, parse_dates=parse_dates)\n",
    "services.loc[services['morning']=='t','morning']=True\n",
    "services.loc[services['morning']=='f','morning']=False\n",
    "services.loc[services['afternoon']=='t','afternoon']=True\n",
    "services.loc[services['afternoon']=='f','afternoon']=False\n",
    "services.loc[services['first_time_of_provider_in_address_cache']=='t','first_time_of_provider_in_address_cache']=True\n",
    "services.loc[services['first_time_of_provider_in_address_cache']=='f','first_time_of_provider_in_address_cache']=False\n",
    "services.to_sql('services', engine, if_exists='replace')\n",
    "print services.columns.to_series().groupby(services.dtypes).groups\n",
    "print services['status'].unique()\n",
    "services.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PAYROLLS\n",
    "payrolls = pd.read_csv(path + 'payrolls.csv', sep=';')\n",
    "payrolls.to_sql('payrolls', engine, if_exists='replace')\n",
    "print payrolls.columns.to_series().groupby(payrolls.dtypes).groups\n",
    "payrolls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PAYROLL TERMS\n",
    "dtypes = {'start_date': 'str', 'end_date': 'str'}\n",
    "parse_dates = ['start_date', 'end_date']\n",
    "payroll_terms = pd.read_csv(path + 'payroll_terms.csv', sep=';',\n",
    "                            dtype=dtypes, parse_dates=parse_dates)\n",
    "payroll_terms.to_sql('payroll_terms', engine, if_exists='replace')\n",
    "print payroll_terms.columns.to_series().groupby(payroll_terms.dtypes).groups\n",
    "payroll_terms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# BANK TRANSACTIONS\n",
    "dtypes = {'date': 'str'}\n",
    "parse_dates = ['date']\n",
    "bank_transactions = pd.read_csv(path + 'bank_transactions.csv', sep=';', \n",
    "                                dtype=dtypes, parse_dates=parse_dates, skiprows = [22131, 24684, 4174, 11432])\n",
    "bank_transactions.to_sql('bank_transactions', engine, if_exists='replace')\n",
    "print bank_transactions.columns.to_series().groupby(bank_transactions.dtypes).groups\n",
    "bank_transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# BANK TRANSACTION TYPES\n",
    "bank_transaction_types = pd.read_csv(path + 'bank_transaction_types.csv', sep=';')\n",
    "bank_transaction_types.to_sql('bank_transaction_types', engine, if_exists='replace')\n",
    "print bank_transaction_types.columns.to_series().groupby(bank_transaction_types.dtypes).groups\n",
    "bank_transaction_types.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SERVICE RATINGS\n",
    "dtypes = {'created_at': 'str'}\n",
    "parse_dates = ['created_at']\n",
    "service_reviews = pd.read_csv(path + 'service_reviews.csv', sep=';',\n",
    "                              dtype=dtypes, parse_dates=parse_dates)\n",
    "service_reviews.drop_duplicates(subset=['service_id'], keep='last', inplace=True)\n",
    "service_reviews.to_sql('service_reviews', engine, if_exists='replace')\n",
    "print service_reviews.columns.to_series().groupby(service_reviews.dtypes).groups\n",
    "service_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PROVIDER RATINGS\n",
    "dtypes = {'created_at': 'str'}\n",
    "parse_dates = ['created_at']\n",
    "provider_reviews = pd.read_csv(path + 'provider_satisfaction_checks.csv',\n",
    "                               sep=';', dtype=dtypes, parse_dates=parse_dates)\n",
    "provider_reviews.to_sql('provider_reviews', engine, if_exists='replace')\n",
    "print provider_reviews.columns.to_series().groupby(provider_reviews.dtypes).groups\n",
    "provider_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# BANS\n",
    "dtypes = {'created_at': 'str'}\n",
    "parse_dates = ['created_at']\n",
    "bans = pd.read_csv(path + 'bans.csv',\n",
    "                               sep=';', dtype=dtypes, parse_dates=parse_dates)\n",
    "bans.to_sql('bans', engine, if_exists='replace')\n",
    "print bans.columns.to_series().groupby(bans.dtypes).groups\n",
    "bans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MISBEHAVIOURS\n",
    "dtypes = {'date': 'str'}\n",
    "parse_dates = ['date']\n",
    "misbehaviors = pd.read_csv(path + 'misbehaviors.csv',\n",
    "                               sep=';', dtype=dtypes, parse_dates=parse_dates, skiprows = [659, 11497])\n",
    "misbehaviors.to_sql('misbehaviors', engine, if_exists='replace')\n",
    "print misbehaviors.columns.to_series().groupby(misbehaviors.dtypes).groups\n",
    "misbehaviors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MISBEHAVIOUR TYPES\n",
    "misbehavior_types = pd.read_csv(path + 'misbehavior_types.csv', sep=';')\n",
    "misbehavior_types.to_sql('misbehavior_types', engine, if_exists='replace')\n",
    "\n",
    "misbehavior_types.loc[misbehavior_types['severe']=='t','severe']=True\n",
    "misbehavior_types.loc[misbehavior_types['severe']=='f','severe']=False\n",
    "print misbehavior_types.columns.to_series().groupby(misbehavior_types.dtypes).groups\n",
    "misbehavior_types.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CLIENTS\n",
    "clients = pd.read_csv(path + 'clients.csv', sep=';')\n",
    "clients.to_sql('clients', engine, if_exists='replace')\n",
    "# work type\n",
    "clients = clients.rename(columns={'nit': 'office'})\n",
    "clients.loc[clients['office']=='t','office']=True\n",
    "clients.loc[clients['office']=='f','office']=False\n",
    "print clients.columns.to_series().groupby(clients.dtypes).groups\n",
    "clients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PROVIDER STATS \n",
    "dtypes = {'date': 'str','created_at':'str', 'updated_at':'str'}\n",
    "parse_dates = ['date', 'created_at', 'updated_at']\n",
    "provider_stats = pd.read_csv(path + 'provider_stats.csv', sep=';', \n",
    "                             dtype=dtypes, parse_dates=parse_dates)\n",
    "provider_stats.to_sql('provider_stats', engine, if_exists='replace')\n",
    "\n",
    "print provider_stats.columns.to_series().groupby(provider_stats.dtypes).groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TERMINATION\n",
    "terminations = pd.read_csv(path + 'providers_updated.csv',sep=';',\n",
    "                        usecols=['id','finish_type','reason_finished'])\n",
    "terminations.fillna('missing',inplace=True)\n",
    "terminations.to_sql('terminations', engine, if_exists='replace')\n",
    "print terminations.columns.to_series().groupby(terminations.dtypes).groups\n",
    "terminations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print out all data available in the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clients\n",
      "provider_stats\n",
      "terminations\n",
      "holidays\n",
      "providers\n",
      "services\n",
      "payrolls\n",
      "payroll_terms\n",
      "bank_transactions\n",
      "bank_transaction_types\n",
      "service_reviews\n",
      "provider_reviews\n",
      "bans\n",
      "misbehaviors\n",
      "misbehavior_types\n"
     ]
    }
   ],
   "source": [
    "for i in engine.table_names():\n",
    "    print i "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
